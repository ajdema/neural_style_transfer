{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1EavnDqoWW-xX6NxdxjdeR2a7XqaOGEeR",
      "authorship_tag": "ABX9TyNlEGGtVEOTu5aBpHm4Gw/y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ajdema/neural_style_transfer/blob/main/painting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "iuRc4ZEtm3c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image\n",
        "import scipy.misc\n",
        "\n",
        "import torch.utils.data\n",
        "import torchvision.datasets as datasets\n",
        "import imageio\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "HbLqFL5vm6Dv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B-mQ-yBL0eE0",
        "outputId": "82b3d72c-7aec-418a-cecd-108e5f774516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Computes the Gram matrix of a given tensor essentially every column is multiplied with every row in the matrix, we can think of the spatial information that was contained in the original representations to have been “distributed”. The Gram matrix instead contains non-localized information about the image, such as texture, shapes, and weights — style!"
      ],
      "metadata": {
        "id": "y3jfGTpInALW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class GramMatrix(nn.Module):\n",
        "\n",
        "    def forward(self, input):\n",
        "        a, b, c, d = input.size()\n",
        "        features = input.view(a * b, c * d)\n",
        "        G = torch.mm(features, features.t())\n",
        "\n",
        "        return G.div(a * b * c * d)"
      ],
      "metadata": {
        "id": "9bBhiaOLm9VW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## StyleCNN Initialization\n",
        "\n",
        "In this section of code, we initialize the StyleCNN object, which is designed for neural style transfer. The key variables and components include:\n",
        "\n",
        "- **Input Images:**\n",
        "  - `style`: Style image for the transfer.\n",
        "  - `content`: Content image to be stylized.\n",
        "  - `pastiche`: Parameterized representation of the stylized image.\n",
        "\n",
        "- **Loss Computation Parameters:**\n",
        "  - `content_layers`: Layers used for computing content loss.\n",
        "  - `style_layers`: Layers used for computing style loss.\n",
        "  - `content_weight`: Weight multiplier for content loss.\n",
        "  \n",
        "  - `style_weight`: Weight multiplier for style loss.\n",
        "\n",
        "- **Pretrained Network:**\n",
        "  - `loss_network`: VGG-19 pretrained network used to obtain intermediate representations.\n",
        "\n",
        "- **Gram Matrix Computation:**\n",
        "  - `gram`: GramMatrix module for computing Gram matrices.\n",
        "\n",
        "- **Loss Computation:**\n",
        "  - `loss`: Mean Squared Error (MSE) loss function for content and style losses.\n",
        "\n",
        "- **Optimizer:**\n",
        "  - `optimizer`: LBFGS optimizer used for optimizing the pastiche image.\n",
        "\n",
        "- **CUDA Availability:**\n",
        "  - `use_cuda`: Boolean indicating whether CUDA (GPU acceleration) is available. If true, moves relevant components to GPU.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Me0XzaGosU6f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class StyleCNN(object):\n",
        "    def __init__(self, style, content, pastiche):\n",
        "        super(StyleCNN, self).__init__()\n",
        "\n",
        "        self.style = style\n",
        "        self.content = content\n",
        "        self.pastiche = nn.Parameter(pastiche.data)\n",
        "\n",
        "        self.content_layers = ['conv_4']\n",
        "        self.style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
        "        self.content_weight = 1\n",
        "        self.style_weight = 1\n",
        "\n",
        "        self.loss_network = models.vgg19(pretrained=True)\n",
        "\n",
        "        self.gram = GramMatrix()\n",
        "        self.loss = nn.MSELoss()\n",
        "        self.optimizer = optim.LBFGS([self.pastiche])\n",
        "\n",
        "        self.use_cuda = torch.cuda.is_available()\n",
        "        if self.use_cuda:\n",
        "            self.loss_network.cuda()\n",
        "            self.gram.cuda()\n",
        "    def train(self):\n",
        "      def closure():\n",
        "          self.optimizer.zero_grad()\n",
        "\n",
        "          pastiche = self.pastiche.clone()\n",
        "          pastiche.data.clamp_(0, 1)\n",
        "          content = self.content.clone()\n",
        "          style = self.style.clone()\n",
        "\n",
        "          content_loss = 0\n",
        "          style_loss = 0\n",
        "\n",
        "          i = 1\n",
        "          not_inplace = lambda layer: nn.ReLU(inplace=False) if isinstance(layer, nn.ReLU) else layer\n",
        "          for layer in list(self.loss_network.features):\n",
        "              layer = not_inplace(layer)\n",
        "              if self.use_cuda:\n",
        "                  layer.cuda()\n",
        "\n",
        "              pastiche, content, style = layer.forward(pastiche), layer.forward(content), layer.forward(style)\n",
        "\n",
        "              if isinstance(layer, nn.Conv2d):\n",
        "                  name = \"conv_\" + str(i)\n",
        "\n",
        "                  if name in self.content_layers:\n",
        "                      content_loss += self.loss(pastiche * self.content_weight, content.detach() * self.content_weight)\n",
        "\n",
        "                  if name in self.style_layers:\n",
        "                      pastiche_g, style_g = self.gram.forward(pastiche), self.gram.forward(style)\n",
        "                      style_loss += self.loss(pastiche_g * self.style_weight, style_g.detach() * self.style_weight)\n",
        "\n",
        "              if isinstance(layer, nn.ReLU):\n",
        "                  i += 1\n",
        "\n",
        "          total_loss = content_loss + style_loss\n",
        "          total_loss.backward()\n",
        "\n",
        "          return total_loss\n",
        "\n",
        "      self.optimizer.step(closure)\n",
        "      return self.pastiche"
      ],
      "metadata": {
        "id": "CMno092wsQhc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some utility functions for loading and saving images."
      ],
      "metadata": {
        "id": "X9wSZ_xrvHEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imsize = 256\n",
        "\n",
        "loader = transforms.Compose([\n",
        "             transforms.Resize(imsize),\n",
        "             transforms.ToTensor()\n",
        "         ])\n",
        "\n",
        "unloader = transforms.ToPILImage()\n",
        "\n",
        "def image_loader(image_name):\n",
        "    image = Image.open(image_name)\n",
        "    image = Variable(loader(image))\n",
        "    image = image.unsqueeze(0)\n",
        "    return image\n",
        "\n",
        "def save_image(input, path):\n",
        "    image = input.data.clone().cpu()\n",
        "\n",
        "    size = (image.size(1), image.size(2), image.size(3))\n",
        "\n",
        "    image = image.view(*size)\n",
        "\n",
        "    image = image.numpy()\n",
        "    image = (image * 255).astype(np.uint8)  # Convert to uint8\n",
        "\n",
        "    image = np.clip(image, 0, 255)\n",
        "\n",
        "    imageio.imsave(path, image.transpose(1, 2, 0))"
      ],
      "metadata": {
        "id": "TKvKuWw-v0Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA Configurations\n",
        "dtype = torch.cuda.FloatTensor if torch.cuda.is_available() else torch.FloatTensor\n",
        "\n",
        "# Content and style\n",
        "path = \"/content/drive/MyDrive/painting_completion/\"\n",
        "style = image_loader(path + \"Mona_Lisa.jpg\").type(dtype)\n",
        "content = image_loader(path + \"Leonardo_da_Vinci_Adoration_of_the_Magi.jpg\").type(dtype)\n",
        "\n",
        "pastiche = image_loader(path + \"Leonardo_da_Vinci_Adoration_of_the_Magi.jpg\").type(dtype)\n",
        "pastiche.data = torch.randn(pastiche.data.size()).type(dtype)\n",
        "\n",
        "num_epochs = 401\n",
        "\n",
        "def main():\n",
        "    global pastiche\n",
        "    style_cnn = StyleCNN(style, content, pastiche)\n",
        "\n",
        "    for i in range(num_epochs):\n",
        "        pastiche = style_cnn.train()\n",
        "\n",
        "        if i % 10 == 0:\n",
        "            print(\"Iteration: %d\" % (i))\n",
        "\n",
        "            path = \"/content/drive/MyDrive/painting_completion/outputs/%d.png\" % i\n",
        "            pastiche.data.clamp_(0, 1)\n",
        "            save_image(pastiche, path)\n",
        "\n",
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mT_rPaRxwqhR",
        "outputId": "55b30001-8a7d-4168-f7c5-4d1d700a31cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration: 0\n",
            "Iteration: 10\n",
            "Iteration: 20\n",
            "Iteration: 30\n",
            "Iteration: 40\n",
            "Iteration: 50\n",
            "Iteration: 60\n",
            "Iteration: 70\n",
            "Iteration: 80\n",
            "Iteration: 90\n",
            "Iteration: 100\n",
            "Iteration: 110\n",
            "Iteration: 120\n",
            "Iteration: 130\n",
            "Iteration: 140\n",
            "Iteration: 150\n",
            "Iteration: 160\n",
            "Iteration: 170\n",
            "Iteration: 180\n",
            "Iteration: 190\n",
            "Iteration: 200\n",
            "Iteration: 210\n",
            "Iteration: 220\n",
            "Iteration: 230\n",
            "Iteration: 240\n",
            "Iteration: 250\n",
            "Iteration: 260\n",
            "Iteration: 270\n",
            "Iteration: 280\n",
            "Iteration: 290\n",
            "Iteration: 300\n",
            "Iteration: 310\n",
            "Iteration: 320\n",
            "Iteration: 330\n",
            "Iteration: 340\n",
            "Iteration: 350\n",
            "Iteration: 360\n",
            "Iteration: 370\n",
            "Iteration: 380\n",
            "Iteration: 390\n",
            "Iteration: 400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KURGFLd6PHC6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}